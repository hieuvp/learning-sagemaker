{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0774271a-22a1-4e5b-8a5e-60291f6b57b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Introduction to the OpenAI Chat Completions API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6399ccd-a723-47fd-864f-82dbe9562a7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[OpenAI's Chat completion API](https://platform.openai.com/docs/api-reference/chat) is capable of generating text in a conversational style in response to a prompt. \n",
    "The API leverages the power of GPT (Generative Pre-trained Transformer) models, such as `gpt-3.5-turbo` or `gpt-4`.\n",
    "Given one or more messages the API will generate a response using the model's understanding of the conversation so far.\n",
    "\n",
    "This lab uses the official `openai` Python library and the `gpt-3.5-turbo` model which strikes a balance between speed and accuracy. \n",
    "The `gpt-4` model is more capable of handling complex instruction and performs better in general but at a higher price point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1b2f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Initialization\n",
    "\n",
    "Before diving in, paste the lab config dictionary from the Cloud Academy lab instructions as the value assigned to `lab_config` below and run the code cell by pressing *shift+enter*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install \"openai<1.0.0\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e28d2574cf5fe1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967566a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "lab_config =  # Paste lab config here\n",
    "\n",
    "for key, value in lab_config.items():\n",
    "    setattr(openai, key, value)\n",
    "print('Finished initialization')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e0c51-b263-4775-8550-6e52273b689f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Your first chat completion\n",
    "\n",
    "You will start by using the chat completion API to generate a response to a prompt asking for a short ice cream shop tagline. \n",
    "Run the code cell below to generate a response to the prompt before the mechanics are explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42de6f0-625a-4db7-aabc-fe1ba9e24def",
   "metadata": {
    "editable": true,
    "id": "check1",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Write a tagline for my ice cream shop that is 10 words or less\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=lab_config[\"engine\"], messages=messages, temperature=0, max_tokens=100\n",
    ")\n",
    "print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b16cf5-1800-4c65-9fef-bb68ca554678",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The chat completions API accepts a list of messages as input.\n",
    "Each message in the `messages` list is comprised of a role and message content.\n",
    "The role can be any of the following:\n",
    "\n",
    "- `user`: The user chatting with the AI assistant\n",
    "- `assistant`: The AI assistant\n",
    "- `system`: Used to modify the behavior of the assistant\n",
    "\n",
    "As seen in the example above, not all roles need to be specified. \n",
    "When used, a `system` message is usually provided first to set the tone of the assitant. \n",
    "If not provided the generic assistant behavior is used. \n",
    "Useful responses can be achieved with a single prompt message, but in general, conversations are represented by alternating `user` and `assistant` messages.\n",
    "\n",
    "The `ChatCompletion.create` method returns a [completion object](https://platform.openai.com/docs/api-reference/chat/object) that contains the generated assistant response content and other metadata.\n",
    "The `messages` list is a required parameter of the create method.\n",
    "[Many parameters](https://platform.openai.com/docs/api-reference/chat/object) can be used to adapt the returned completion object.\n",
    "The ones used in this lab are:\n",
    "\n",
    "- `engine`: One way of specifying the model to use.\n",
    "- `temperature`: A measure of randomness in the generated response. Must be a value between 0 and 2 where 0 is deterministic and 2 is very random.\n",
    "- `max_tokens`: The maximum number of tokens to generate. A token is a chunk of text the language model reads or write. This lab limits to 100 to minimize the impact of rate-limiting.\n",
    "\n",
    "The completion object can include multiple response choices but by default, only one is returned.\n",
    "This behavior can be modified by setting the `n` parameter to the number of response choices desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34472252",
   "metadata": {},
   "source": [
    "#### Refactoring the chat completion API call\n",
    "\n",
    "As a good programming practice and to make the code more readable, you will refactor the API call into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93c3392-9c3c-4161-a2cc-c7b7e9052c32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def completion(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=lab_config[\"engine\"], messages=messages, temperature=0, max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf93341",
   "metadata": {},
   "source": [
    "Now you can focus more on the messages having refactored the completion code to a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f61798",
   "metadata": {},
   "source": [
    "#### Using system messages\n",
    "\n",
    "As discussed earlier, system messages are used to modify the behavior of the assistant.\n",
    "The following introduces a system message to influence the style of the response to the same `user` prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e8fbb-a700-4128-be10-6eab57e16259",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Write a tagline for my ice cream shop that is 10 words or less\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a poet that rhymes in the style of Dr. Seuss\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "print(completion(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31845fe",
   "metadata": {},
   "source": [
    "The generic assistant is useful in many situations but the system message allows you to change the style of the response when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6321b7",
   "metadata": {},
   "source": [
    "#### Conversational context\n",
    "\n",
    "By including previous messages between the user and assistant in the `messages` list, the assistant can use the context to generate a more relevant response.\n",
    "The assistant messages can be previously generated messages or they can be written by you to provide examples of how you want the assistant to respond.\n",
    "\n",
    "The following example demonstrates this by including a couple of messages exchanged between the user and the assistant about an exclusive ice cream flavor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a tagline for my ice cream shop that is 10 words or less\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a poet that rhymes in the style of Dr. Seuss\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"We sell only one flavor of ice cream at my ice cream shop, vanilla\",\n",
    "    },\n",
    "    {\"role\": \"assistant\", \"content\": \"You have to be odd to be number one\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "print(completion(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940aec76",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "In this lab, you learned how to use the OpenAI chat completion API to generate text in a conversational style.\n",
    "You use the OpenAI Python library to call the API.\n",
    "The messages provided to the API are for three different roles: user, assistant, and system.\n",
    "The model can use the context of the conversation to generate a more relevant response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
